{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from satlomas.configuration import LSTMTrainingScriptConfig\n",
    "\n",
    "from satlomas.data import read_time_series_from_csv\n",
    "from satlomas.feature import (\n",
    "    get_dataset_from_series,\n",
    "    get_interest_variable\n",
    ")\n",
    "from satlomas.model import (\n",
    "    build_lstm_nnet,\n",
    "    eval_regression_performance,\n",
    "    fit_model,\n",
    "    train_val_test_split\n",
    ")\n",
    "from satlomas.model_opt import get_lstm_nnet_opt\n",
    "\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "\n",
    "    config_file = '../config_train_lstm_temp.json'\n",
    "    script_config = LSTMTrainingScriptConfig(config_file)\n",
    "\n",
    "    n_past_steps = script_config.n_past_steps\n",
    "    input_csv = script_config.input_csv\n",
    "\n",
    "    date_col = script_config.date_col\n",
    "    hr_col = script_config.hr_col\n",
    "    numeric_var = script_config.numeric_var\n",
    "    sensor_var = script_config.sensor_var\n",
    "    target_sensor = script_config.target_sensor\n",
    "    output_models_path = script_config.output_models_path\n",
    "    output_results_path = script_config.output_results_path\n",
    "\n",
    "    base_config = script_config.base_config\n",
    "    mid_layers_config = script_config.mid_layers_config\n",
    "    model_loss = script_config.model_loss\n",
    "    optimizer = script_config.optimizer\n",
    "\n",
    "    early_stop_patience=script_config.early_stop_patience\n",
    "    epochs=script_config.epochs\n",
    "    \n",
    "    # read the raw data\n",
    "    input_csv_nb = '../{}'.format(input_csv)\n",
    "    raw_dataset = read_time_series_from_csv(input_csv_nb,date_col,hr_col,numeric_var,sensor_var)\n",
    "    raw_dataset.head()\n",
    "    \n",
    "    # get the time series dataset\n",
    "    time_series_dset = get_interest_variable(raw_dataset,sensor_var,date_col,hr_col,numeric_var,target_sensor)\n",
    "    time_series_dset.head()\n",
    "    \n",
    "    # get the final dataset\n",
    "    sup_dataset,scaler = get_dataset_from_series(time_series_dset,n_past_steps)\n",
    "    print(scaler)\n",
    "    sup_dataset.head()\n",
    "    \n",
    "    # split the dataset in train , test and validation\n",
    "    n_features = time_series_dset.shape[1]\n",
    "    dataset_splits = train_val_test_split(sup_dataset,n_past_steps,n_features,numeric_var)\n",
    "    \n",
    "    train_X = dataset_splits['trainset']['X']\n",
    "    train_y = dataset_splits['trainset']['y']\n",
    "    \n",
    "    val_X = dataset_splits['valset']['X']\n",
    "    val_y = dataset_splits['valset']['y']\n",
    "    \n",
    "    return train_X, train_y, val_X, val_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_nnet = build_lstm_nnet(trainset['X'],base_config,mid_layers_config,model_loss,optimizer)\n",
    "lstm_nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_range = base_config['first_layer']['dropout_range']\n",
    "dropout_range[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    from datetime import datetime\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from satlomas.configuration import LSTMTrainingScriptConfig\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from satlomas.data import read_time_series_from_csv\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from satlomas.feature import get_dataset_from_series, get_interest_variable\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from satlomas.model import build_lstm_nnet, eval_regression_performance, fit_model, train_val_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from satlomas.model_opt import get_lstm_nnet_opt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'rate': hp.uniform('rate', 0,0.5),\n",
      "        'rate_1': hp.uniform('rate_1', 0,0.5),\n",
      "        'rate_2': hp.uniform('rate_2', 0,0.5),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: \n",
      "   3: config_file = '../config_train_lstm_temp.json'\n",
      "   4: script_config = LSTMTrainingScriptConfig(config_file)\n",
      "   5: \n",
      "   6: n_past_steps = script_config.n_past_steps\n",
      "   7: input_csv = script_config.input_csv\n",
      "   8: \n",
      "   9: date_col = script_config.date_col\n",
      "  10: hr_col = script_config.hr_col\n",
      "  11: numeric_var = script_config.numeric_var\n",
      "  12: sensor_var = script_config.sensor_var\n",
      "  13: target_sensor = script_config.target_sensor\n",
      "  14: output_models_path = script_config.output_models_path\n",
      "  15: output_results_path = script_config.output_results_path\n",
      "  16: \n",
      "  17: base_config = script_config.base_config\n",
      "  18: mid_layers_config = script_config.mid_layers_config\n",
      "  19: model_loss = script_config.model_loss\n",
      "  20: optimizer = script_config.optimizer\n",
      "  21: \n",
      "  22: early_stop_patience=script_config.early_stop_patience\n",
      "  23: epochs=script_config.epochs\n",
      "  24: \n",
      "  25: # read the raw data\n",
      "  26: input_csv_nb = '../{}'.format(input_csv)\n",
      "  27: raw_dataset = read_time_series_from_csv(input_csv_nb,date_col,hr_col,numeric_var,sensor_var)\n",
      "  28: raw_dataset.head()\n",
      "  29: \n",
      "  30: # get the time series dataset\n",
      "  31: time_series_dset = get_interest_variable(raw_dataset,sensor_var,date_col,hr_col,numeric_var,target_sensor)\n",
      "  32: time_series_dset.head()\n",
      "  33: \n",
      "  34: # get the final dataset\n",
      "  35: sup_dataset,scaler = get_dataset_from_series(time_series_dset,n_past_steps)\n",
      "  36: print(scaler)\n",
      "  37: sup_dataset.head()\n",
      "  38: \n",
      "  39: # split the dataset in train , test and validation\n",
      "  40: n_features = time_series_dset.shape[1]\n",
      "  41: dataset_splits = train_val_test_split(sup_dataset,n_past_steps,n_features,numeric_var)\n",
      "  42: \n",
      "  43: train_X = dataset_splits['trainset']['X']\n",
      "  44: train_y = dataset_splits['trainset']['y']\n",
      "  45: \n",
      "  46: val_X = dataset_splits['valset']['X']\n",
      "  47: val_y = dataset_splits['valset']['y']\n",
      "  48: \n",
      "  49: \n",
      "  50: \n",
      "  51: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4: \n",
      "   5: \n",
      "   6: \tn_input_neurons = train_X.shape[1]\n",
      "   7: \n",
      "   8: \n",
      "   9: \tmodel = Sequential() \n",
      "  10: \tmodel.add(\n",
      "  11: \t\tLSTM(\n",
      "  12: \t\t\tchoice([2, 3]) * n_input_neurons,\n",
      "  13: \t\t\tinput_shape=(n_input_neurons, train_X.shape[2]),\n",
      "  14: \t\t\treturn_sequences=True\n",
      "  15: \t\t\t)\n",
      "  16: \t\t)\n",
      "  17: \tmodel.add(Dropout(rate=space['rate']))\n",
      "  18: \n",
      "  19: \n",
      "  20: \tn_mid_layers = 1\n",
      "  21: \tmid_layers_mult = 3\n",
      "  22: \tfor i in range(n_mid_layers):\n",
      "  23: \t\tmodel.add(LSTM(mid_layers_mult * n_input_neurons, return_sequences=True)) \n",
      "  24: \t\tmodel.add(Dropout(rate=space['rate_1']))\n",
      "  25: \t\n",
      "  26: \tlast_layer_mult = 2\n",
      "  27: \tmodel.add(last_layer_mult * n_input_neurons)\n",
      "  28: \tmodel.add(Dropout(rate=space['rate_2']))\n",
      "  29: \t\n",
      "  30: \tmodel.add(Dense(1))\n",
      "  31: \n",
      "  32: \tmodel_loss = 'mean_squared_error'\n",
      "  33: \n",
      "  34: \tmodel.compile(loss=model_loss, metrics=['accuracy'],\n",
      "  35: \t\t\t\t  optimizer=space['optimizer'])\n",
      "  36: \n",
      "  37: \n",
      "  38: \tearly_stop_patience = 10\n",
      "  39: \t\n",
      "  40: \tearly_stopping = EarlyStopping(\n",
      "  41: \t\tmonitor='val_loss', \n",
      "  42: \t\tpatience=early_stop_patience, \n",
      "  43: \t\tverbose=1, mode='min',\n",
      "  44: \t\trestore_best_weights=True)\n",
      "  45: \n",
      "  46: \ttime_stmp = datetime.now()\n",
      "  47:  \n",
      "  48: \ttime_stmp_str = time_stmp.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
      "  49: \n",
      "  50: \toutput_models_path = 'models/'\n",
      "  51: \n",
      "  52: \tout_model_name = '{}_hyperas_model_{}.hdf5'.format(\n",
      "  53: \t\t\toutput_models_path,\n",
      "  54: \t\t\ttime_stmp_str)\n",
      "  55: \n",
      "  56: \thistory_out_name = '{}_hyperas_history_{}.pickle'.format(\n",
      "  57: \t\t\toutput_models_path,\n",
      "  58: \t\t\ttime_stmp_str)\n",
      "  59: \n",
      "  60: \tcheckpoint = ModelCheckpoint(\n",
      "  61: \t\tout_model_name, \n",
      "  62: \t\tsave_best_only=True, \n",
      "  63: \t\tmonitor='val_loss', \n",
      "  64: \t\tmode='min',verbose=2)\n",
      "  65: \n",
      "  66: \t\n",
      "  67: \tresult = model.fit(\n",
      "  68: \t\ttrain_X, train_y,\n",
      "  69: \t\tbatch_size=space['batch_size'],\n",
      "  70: \t\tepochs=epochs,\n",
      "  71: \t\tvalidation_data=(val_X, val_y),\n",
      "  72: \t\tverbose=1, shuffle=False,callbacks=[checkpoint,early_stopping])\n",
      "  73: \n",
      "  74: \twith open(history_out_name, 'wb') as file_pi:\n",
      "  75: \t\tpickle.dump(result, file_pi)\n",
      "  76: \n",
      "  77: \tvalidation_acc = np.amax(result.history['val_acc']) \n",
      "  78: \tprint('Best validation acc of epoch:', validation_acc)\n",
      "  79: \n",
      "  80: \tprint('Returning saved model {}'.format(out_model_name))\n",
      "  81: \tmodel = load_model(out_model_name)\n",
      "  82: \treturn {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      "  83: \n",
      "read dataset of shape (160584, 3)\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "Sampleamos datasets de futuro a pasado\n",
      "(96348, 3) 96348 (96348,)\n",
      "(96348, 3, 1) (96348,) (32116, 3, 1) (32116,) (32117, 3, 1) (32117,)\n",
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: name 'Sequential' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-4d3b0ab5e886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                           \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                           \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                       notebook_name='Sensor predictions with module')\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dsvenv/lib/python3.6/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dsvenv/lib/python3.6/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[1;32m    137\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m              return_argmin=True),\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     )\n",
      "\u001b[0;32m~/.virtualenvs/dsvenv/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dsvenv/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         )\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dsvenv/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dsvenv/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dsvenv/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dsvenv/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dsvenv/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             )\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desarrollos/satlomas-exp/meteorologica/temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[0;34m(space)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "#time_stmp = datetime.now()\n",
    " \n",
    "#time_stmp_str = time_stmp.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "#out_model_name = '{}{}_hyperas_model_{}.hdf5'.format(\n",
    "#        output_models_path,\n",
    "#        str(script_config),\n",
    "#        time_stmp_str)\n",
    "\n",
    "#history_out_name = '{}{}_hyperas_history_{}.pickle'.format(\n",
    "#        output_models_path,\n",
    "#        str(script_config),\n",
    "#        time_stmp_str)\n",
    "\n",
    "\n",
    "#def get_params():\n",
    "#    return dataset_splits,base_config,mid_layers_config,model_loss,['rmsprop', 'adam', 'sgd'],sensor_var,numeric_var,output_models_path,early_stop_patience,epochs,time_stmp_str,out_model_name,history_out_name\n",
    "    \n",
    "best_run, best_model = optim.minimize(model=get_lstm_nnet_opt,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=3,\n",
    "                                          trials=Trials(),\n",
    "                                      notebook_name='Sensor predictions with module')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
